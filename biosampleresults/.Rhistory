if(plot_dist_Area){
quartz(height=3.5,width=6)
plot(density_dist, xlab=expression("Area of the detected particles"~(log10(px^2))), ylab="Density", main="", bty = "n", lwd = 2)
abline(v= (density_dist$x[tp$pits][1]),col="red")
if(remove_large_outliers) abline(v= (cutoff_outliers),col="red")
}
## create the count table now
counts_filt=subset(counts,log10(Area)< cutoff_outliers & log10(Area)>(density_dist$x[tp$pits][1]))
labels_from_id=tstrsplit(strsplit(counts_filt$id,file_extension),"_")
temp_data_frame=unique(data.frame(labels_from_id))
temp_data_frame=cbind(temp_data_frame,tapply(counts_filt$Major, counts_filt$id, length))
if(is.na(vec_names)){
names(temp_data_frame)=c(paste0("ID_",1:length(labels_from_id)),"nb_eggs")
}else{
names(temp_data_frame)=c(vec_names,"nb_eggs")
}
setwd(temp_dir)
return(list(temp_data_frame,counts_filt))
}
produce_counts_from_tables()[[1]]
produce_counts_from_tables()[[1]]
produce_counts_from_tables <- function(directory_path="/Users/ctern/Downloads/images/070119-36/0920", file_extension=".xls",
user_bw=.2, min_px_Area=5, plot_dist_Area=FALSE, remove_large_outliers=TRUE, vec_names=NA){
#user_bw: bandwidth used to compute the kernel density estimates of the Area distribution (see ?density)
#min_px_Area: lower threshold that can be used to remove small dust particles. This threshold should not be set to the minimal expected Area of an egg (the first peak of a bimodal distribution is always removed in a later step)
#plot_dist_Area: if TRUE, the function will plot the Area distribution with the cutoff used to remove outliers (Boolean)
#remove_large_outliers: if TRUE, large particles are also removed from the final egg count
#vec_names: each file name will be split using the "_" separator into several column to create a final data frame. The column names default values will be set to "ID_#" unless specified in vec_names.
temp_dir=getwd()
setwd(directory_path)
all_files=list.files(path=directory_path, pattern= file_extension)
cat(sprintf("Loading input data from %s files... ", length(all_files)))
read_all=lapply(all_files,read.table,sep="\t",header=TRUE)
cat(sprintf("DONE\n"))
counts=do.call(rbind,read_all)
nb_lines_per_file=sapply(all_files,countLines)-1
#Should be TRUE
#sum(nb_lines_per_file)==nrow(counts)
## Add a column with the name of the file #id
counts$id=rep(all_files, nb_lines_per_file)
#counts=subset(counts,Area>= min_px_Area & counts$Major/counts$Minor < quantile(counts$Major/counts$Minor, .9999))
counts=subset(counts,Area >= min_px_Area)
density_dist=density(log10(counts$Area),bw=user_bw)
tp=suppressWarnings(turnpoints(density_dist$y))
# We use the first pit as the cutoff
#(density_dist$x[tp$pits])[1]
cat(sprintf("Remove %s small outliers (%s %%)\n", nrow(subset(counts,log10(Area)< density_dist$x[tp$peaks][1])),round(10000*nrow(subset(counts,log10(Area)< density_dist$x[tp$peaks][1]))/nrow(counts))/100))
cutoff_outliers=Inf
if(remove_large_outliers){
cutoff_outliers=density_dist$x[tp$peaks][2]+2*(density_dist$x[tp$peaks][2]-density_dist$x[tp$pits][1])
cat(sprintf("Remove %s large outliers (%s %%)\n", nrow(subset(counts,Area> 10^cutoff_outliers)),round(1000*nrow(subset(counts,Area > 10^cutoff_outliers))/nrow(counts))/10))
}
########
if(plot_dist_Area){
quartz(height=3.5,width=6)
plot(density_dist, xlab=expression("Area of the detected particles"~(log10(px^2))), ylab="Density", main="", bty = "n", lwd = 2)
abline(v= (density_dist$x[tp$pits][1]),col="red")
if(remove_large_outliers) abline(v= (cutoff_outliers),col="red")
}
## create the count table now
counts_filt=subset(counts,log10(Area)< cutoff_outliers & log10(Area)>(density_dist$x[tp$pits][1]))
labels_from_id=tstrsplit(strsplit(counts_filt$id,file_extension),"_")
temp_data_frame=unique(data.frame(labels_from_id))
temp_data_frame=cbind(temp_data_frame,tapply(counts_filt$Major, counts_filt$id, length))
if(is.na(vec_names)){
names(temp_data_frame)=c(paste0("ID_",1:length(labels_from_id)),"nb_eggs")
}else{
names(temp_data_frame)=c(vec_names,"nb_eggs")
}
setwd(temp_dir)
return(list(temp_data_frame,counts_filt))
}
produce_counts_from_tables()[[1]]
produce_counts_from_tables()[[1]]
produce_counts_from_tables <- function(directory_path="/Users/ctern/Downloads/images/070119-36/0922", file_extension=".xls",
user_bw=.2, min_px_Area=5, plot_dist_Area=FALSE, remove_large_outliers=TRUE, vec_names=NA){
#user_bw: bandwidth used to compute the kernel density estimates of the Area distribution (see ?density)
#min_px_Area: lower threshold that can be used to remove small dust particles. This threshold should not be set to the minimal expected Area of an egg (the first peak of a bimodal distribution is always removed in a later step)
#plot_dist_Area: if TRUE, the function will plot the Area distribution with the cutoff used to remove outliers (Boolean)
#remove_large_outliers: if TRUE, large particles are also removed from the final egg count
#vec_names: each file name will be split using the "_" separator into several column to create a final data frame. The column names default values will be set to "ID_#" unless specified in vec_names.
temp_dir=getwd()
setwd(directory_path)
all_files=list.files(path=directory_path, pattern= file_extension)
cat(sprintf("Loading input data from %s files... ", length(all_files)))
read_all=lapply(all_files,read.table,sep="\t",header=TRUE)
cat(sprintf("DONE\n"))
counts=do.call(rbind,read_all)
nb_lines_per_file=sapply(all_files,countLines)-1
#Should be TRUE
#sum(nb_lines_per_file)==nrow(counts)
## Add a column with the name of the file #id
counts$id=rep(all_files, nb_lines_per_file)
#counts=subset(counts,Area>= min_px_Area & counts$Major/counts$Minor < quantile(counts$Major/counts$Minor, .9999))
counts=subset(counts,Area >= min_px_Area)
density_dist=density(log10(counts$Area),bw=user_bw)
tp=suppressWarnings(turnpoints(density_dist$y))
# We use the first pit as the cutoff
#(density_dist$x[tp$pits])[1]
cat(sprintf("Remove %s small outliers (%s %%)\n", nrow(subset(counts,log10(Area)< density_dist$x[tp$peaks][1])),round(10000*nrow(subset(counts,log10(Area)< density_dist$x[tp$peaks][1]))/nrow(counts))/100))
cutoff_outliers=Inf
if(remove_large_outliers){
cutoff_outliers=density_dist$x[tp$peaks][2]+2*(density_dist$x[tp$peaks][2]-density_dist$x[tp$pits][1])
cat(sprintf("Remove %s large outliers (%s %%)\n", nrow(subset(counts,Area> 10^cutoff_outliers)),round(1000*nrow(subset(counts,Area > 10^cutoff_outliers))/nrow(counts))/10))
}
########
if(plot_dist_Area){
quartz(height=3.5,width=6)
plot(density_dist, xlab=expression("Area of the detected particles"~(log10(px^2))), ylab="Density", main="", bty = "n", lwd = 2)
abline(v= (density_dist$x[tp$pits][1]),col="red")
if(remove_large_outliers) abline(v= (cutoff_outliers),col="red")
}
## create the count table now
counts_filt=subset(counts,log10(Area)< cutoff_outliers & log10(Area)>(density_dist$x[tp$pits][1]))
labels_from_id=tstrsplit(strsplit(counts_filt$id,file_extension),"_")
temp_data_frame=unique(data.frame(labels_from_id))
temp_data_frame=cbind(temp_data_frame,tapply(counts_filt$Major, counts_filt$id, length))
if(is.na(vec_names)){
names(temp_data_frame)=c(paste0("ID_",1:length(labels_from_id)),"nb_eggs")
}else{
names(temp_data_frame)=c(vec_names,"nb_eggs")
}
setwd(temp_dir)
return(list(temp_data_frame,counts_filt))
}
produce_counts_from_tables()[[1]]
library(data.table)
library(gdata)
library(cowplot)
library(data.table)
library(foreach)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
source('~/Downloads/GitHub/simCline/biosampleresults/makePlots.R', echo=TRUE)
setwd("~/Downloads/GitHub/simCline/biosampleresults")
samps <- fread("./concatenated.csv")
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(lat),
long=mean(long)),
list(state, year, country)]
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(which[lat!="NA"]),
long=mean(which[long!="NA"])),
list(state, year, country)]
lat.num<- as.numeric(which[lat!="NA"])
lat.num<- as.numeric(which[samps.lat!="NA"])
samps <- fread("./concatenated.csv")
lat.num<- as.numeric(which[samps[lat]!="NA"])
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(which[samps[lat]!="NA"]),
long=mean(which[samps[long]!="NA"])),
list(state, year, country)]
lat.num<- as.numeric(which[samps[lat]!="NA"])
samps
samps[lat]
samps$lat
as.numeric(which[samps$lat!="NA"])
as.integer(which[samps$lat!="NA"])
as.integer(which(samps$lat!="NA"))
as.numeric(which(samps$lat!="NA"))
as.numeric(as.character(which(samps$lat!="NA")))
which(samps$lat!="NA")
samps$lat
which(samps$lat!="NA")
mean(which(samps[lat]!="NA"))
which(samps$lat!="NA")
lat[which(samps$lat!="NA")]
samps$lat[which(samps$lat!="NA")]
mean(samps$lat[which(samps$lat!="NA")])
long=mean(samps$long[which(samps$long!="NA")])
mean(samps$long[which(samps$long!="NA")])
colnames(samps)
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]),
list(state, year, country)]
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]),
list(state, year, country) ]
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]),
list(state, year, country) ]
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]) ),
list(state, year, country) ]
samps.ag
setkey(samps.ag, state, year)
setkey(samps, state, year)
world <- as.data.table(map_data("world"))
samps.ag.ag <- samps.ag[,list(n=sum(nTime), lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]) ),
list(state) ]
library(maps)
load.package(maps)
package(maps)
install.packages(maps)
install.packages("maps")
library("maps")
samps.ag.ag <- samps.ag[,list(n=sum(nTime), lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]) ),
list(state) ]
min.lat.eu <- 35
max.lat.eu <- 55
min.long.eu <- -10
max.long.eu <- 37
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=I((n-1)/2 + 4)), alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
world <- as.data.table(map_data("world"))
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=I((n-1)/2 + 4)), alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
samps.ag
samps.ag.ag <- samps.ag[,list(n=sum(nTime), lat=samps$lat,
long=samps$long ),
list(state) ]
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=I((n-1)/2 + 4)), alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
samps.ag.ag
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=I((n-1)/2 + 4)), alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
map_data("world")
world <- as.data.table(map_data("world"))
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=I((n-1)/2 + 4)), alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
world
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
samps.ag.ag
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]) ),
list(state, year, country) ]
setkey(samps.ag, country, year)
setkey(samps, country, year)
world <- as.data.table(map_data("world"))
samps.ag.ag <- samps.ag[,list(n=sum(nTime), lat=samps$lat,
long=samps$long ),
list(country) ]
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=I((n-1)/2 + 4)), alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
world <- as.data.table(map_data("world"))
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=3, alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=3, alpha=.5)
+
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
## north america
min.lat.na <- 25
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=3, alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=3, alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
## north america
min.lat.na <- 25
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, size=3), alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
world
world <- 	ggplot() +
geom_polygon(data = world,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat), size=3, alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
worldData <- as.data.table(map_data("world"))
world <- 	ggplot() +
geom_polygon(data = worldData,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat), size=3, alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
world
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
worldData
gds.file <- seqOpen(gds.output)
library(SeqArray)
vcf.file <- "~/Downloads/GitHub/simCline/biosampleresults/pooledData.vcf"
gds.output <- "~/Downloads/GitHub/simCline/biosampleresults/pooledData.gds"
seqVCF2GDS(vcf.fn = vcf.file, out.fn = gds.output)
gds.file <- seqOpen(gds.output)
snp.dt <- data.frame(chr=seqGetData(gds.file, "chromosome"),
pos=seqGetData(gds.file, "position"),
nAlleles=seqGetData(gds.file, "$num_allele"),
id=seqGetData(gds.file, "variant.id"),
seqMissing(gds.file, per.variant=T))
table(snp.dt$chr)
prop.table(table(snp.dt$nAlleles))
seqSetFilter(gds.file, variant.id=snp.dt[nAlleles==2])
nAlleles=seqGetData(gds.file, "$num_allele")
seqSetFilter(gds.file, variant.id=snp.dt[nAlleles==2])
??seqSetFilter
snp.dt[nAlleles==2]
seqSetFilter(gds.file, variant.id=snp.dt[nAlleles==2])
seqSetFilter(gds.file, variant.id=snp.dt[nAlleles==2]$id)
seqGetData(gds.file, “annotation/format/AD”)
??seqGetData
View(gds.file)
seqGetData(gds.file, “annotation/format/AD”)
seqGetData(gds.file, “annotation/info/AD”)
seqSetFilter(gds.file, variant.id=snp.dt[which(nAlleles==2]))
seqSetFilter(gds.file, variant.id=snp.dt[which(nAlleles==2)])
snp.dt[ which(nAlleles==2) ]
seqSetFilter(gds.file, variant.id=snp.dt[ which(snp.dt$nAlleles==2) ] )
seqSetFilter(gds.file, variant.id=snp.dt[which(snp.dt$nAlleles==2)]$id)
snp.dt[ which(snp.dt$nAlleles==2) ]
snp.dt$nAllele
snp.dt$nAlleles
snp.dt$nAll
which(snp.dt$nAlleles==2), ]
snp.dt[ which(snp.dt$nAlleles==2), ]
seqSetFilter(gds.file, variant.id=snp.dt[ which(snp.dt$nAlleles==2), ] )
seqSetFilter(gds.file, variant.id=snp.dt[which(snp.dt$nAlleles==2), ]$id)
seqGetData(gds.file, “annotation/format/AD”)
samps.ag.ag
samps.ag
samps
samps.ag.ag <- samps.ag[,list(n=sum(nTime), lat=samps$lat,
long=samps$long,
pool.indiv=samps$`p/i`),
list(country) ]
library(data.table)
library(gdata)
library(cowplot)
library(data.table)
library(foreach)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
### set working directory
setwd("/scratch/cat7ep/simCline/biosampleresults")
getwd()
### load data
samps <- fread("./concatenated.csv")
### time plot
### find sites with multiple time points
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]) ),
list(state, year, country) ]
setkey(samps.ag, country, year)
setkey(samps, country, year)
worldData <- as.data.table(map_data("world"))
samps.ag.ag <- samps.ag[,list(n=sum(nTime), lat=samps$lat,
long=samps$long,
pool.indiv=samps$`p/i`),
list(country) ]
min.lat.eu <- 35
max.lat.eu <- 55
min.long.eu <- -10
max.long.eu <- 37
# size=I((n-1)/2 + 4))
world <- 	ggplot() +
geom_polygon(data = worldData,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, color=pool.indiv), size=3, alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
world
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
??seqGetData
View(samps)
gds.output <- "~/Downloads/GitHub/simCline/biosampleresults/pooledData.gds"
seqGetData(gds.output, “annotation/format/AD”)
seqGetData(gds.file, “annotation/format/AD”)
gds.file
seqGetData(gds.file, “annotation/format/AD”)
??seqExampleFileName
??seqGetData
# seqSetFilter(gds.file, variant.id=snp.dt[ which(snp.dt$nAlleles==2), ] )
seqSetFilter(gds.file, variant.id=snp.dt[which(snp.dt$nAlleles==2), ]$id)
seqGetData(gds.file, “annotation/format/AD”)
seqGetData(gds.file, "annotation/format/AD" )
seqGetData(gds.file, "annotation/format/RD" )
snp.dt
print(snp.dt)
samps <- fread("./concatenated.csv")
rbind(samps, "./concatenatedEuro.csv")
samps
### load data
samps <- rbind("./concatenated.csv", "./concatenatedEuro.csv")
samps
rbind(samps, as.data.frame("./concatenatedEuro.csv"))
### load data
samps <- fread("./concatenated.csv")
rbind(samps, as.data.frame("./concatenatedEuro.csv"))
as.data.frame("./concatenatedEuro.csv")
as.data.frame(./concatenatedEuro.csv)
rbind(samps, fread("./concatenatedEuro.csv"))
### load data
samps <- fread("./concatenated.csv")
samps <- rbind(samps, fread("./concatenatedEuro.csv"))
### time plot
### find sites with multiple time points
samps.ag <- samps[,list(nSamps=length(row),
nTime=length( unique(samps[,c('year','month','day')]) ),
lat=mean(samps$lat[which(samps$lat!="NA")]),
long=mean(samps$long[which(samps$long!="NA")]) ),
list(state, year, country) ]
setkey(samps.ag, country, year)
setkey(samps, country, year)
worldData <- as.data.table(map_data("world"))
samps.ag.ag <- samps.ag[,list(n=sum(nTime), lat=samps$lat,
long=samps$long,
pool.indiv=samps$`p/i`),
list(country) ]
min.lat.eu <- 35
max.lat.eu <- 55
min.long.eu <- -10
max.long.eu <- 37
# size=I((n-1)/2 + 4))
world <- 	ggplot() +
geom_polygon(data = worldData,
aes(x=long, y = lat, group = group), fill="lightgrey") +
geom_point(data = samps.ag.ag,
aes(x=long, y=lat, color=pool.indiv), size=3, alpha=.5) +
xlab("Longitude") + ylab("Latitude") + scale_fill_manual(values="black")
world
ggsave(world, file="./worldPlot.pdf", height=4, width=6)
seqGetData(gds.file, "annotation/format/AD" )
head(seqGetData(gds.file, "annotation/format/RD" ))
??head
seqGetData(gds.file, "annotation/format/AD"$data )
seqGetData(gds.file, "annotation/format/AD", .padNA=TRUE )
seqGetData(gds.file, "annotation/format/AD", padNA=TRUE)
??seqGetData
seqGetData(gds.file, "annotation/format/AD")
seqGetData(gds.file, "annotation/info/AD")
gds.file[,339316]
getClass(seqGetData(gds.file, "annotation/info/AD"))
seqGetData(gds.file, "annotation/info/AD")
getClass(seqGetData(gds.file, "annotation/format/AD"))
class(seqGetData(gds.file, "annotation/format/AD"))
adList<- seqGetData(gds.file, "annotation/format/AD")
print(adList[1])
print(adList[1]$data)
print(adList[2]$data)
print(adList[2])
rdList<- seqGetData(gds.file, "annotation/format/RD" )
rdList[1]
rdList[1]$data
rdList[1]$data
??seqSetFilter
seqGetData(gds.file,"genotype")
dim(adList)
dim(rdList)
??dim
adList<- seqGetData(gds.file, "annotation/format/AD")
adList
dim(adList)
rdList<- seqGetData(gds.file, "annotation/format/RD" )
size(snp.dt)
dim(snp.dt)
table(snp.dt$chr)
